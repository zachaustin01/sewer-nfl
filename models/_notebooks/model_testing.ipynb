{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "REPO_NAME = 'sewer-nfl'\n",
    "CWD = str(os.getcwd())\n",
    "REPO_DIR = CWD[:CWD.find(REPO_NAME)+len(REPO_NAME)]\n",
    "sys.path.insert(0,REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zacha\\Documents\\GitHub\\sewer-nfl\\models\\_utilities\\data\\pipe_layer.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from models._utilities.data.pipe_layer import build_training_dataset\n",
    "from warehouse.config import Configuration # At model level, swictch this to model's config\n",
    "config = Configuration()\n",
    "t = build_training_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NUMERIC_META_COLS = [\n",
    "    'season',\n",
    "    'week',\n",
    "    'spread_line',\n",
    "    'home_score',\n",
    "    'away_score',\n",
    "    'home_cover',\n",
    "    'within_three'\t\n",
    "]\n",
    "\n",
    "class Chrystal_Ball:\n",
    "    '''\n",
    "\n",
    "    Model object designed to generate predictions on a series of live or test data\n",
    "    - Will be stored as a .pkl file\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 training_data,\n",
    "                 test_years = [2022],\n",
    "                 response = 'home_cover', # Options: ['home_cover','spread_line','within_three']\n",
    "                 ):\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.test_years = test_years\n",
    "        self.response = response\n",
    "\n",
    "        self.predictors = [c for c in self.training_data.columns if c not in \\\n",
    "                           NUMERIC_META_COLS and c in self.training_data.select_dtypes(np.number)]\n",
    "\n",
    "        self.train_test_split()\n",
    "        self.model = XGBClassifier(eta = 0.01, reg_lambda=1, min_child_weight=1)\n",
    "        self.params = {\"objective\": \"multi:softprob\", \"tree_method\": \"gpu_hist\", \"num_class\": 2}\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def train_test_split(\n",
    "            self,\n",
    "            mode = 'years'\n",
    "    ):\n",
    "        if mode == 'years':\n",
    "            mask = self.training_data['season'].isin(self.test_years)\n",
    "            self.train_data = self.training_data[~mask]\n",
    "            self.test_data = self.training_data[mask]\n",
    "\n",
    "        self.X_train = self.train_data[self.predictors]\n",
    "        self.X_test = self.test_data[self.predictors]\n",
    "        self.y_train = self.train_data[self.response]\n",
    "        self.y_test = self.test_data[self.response]\n",
    "        self.dtrain = xgb.DMatrix(self.X_train, self.y_train, enable_categorical=True)\n",
    "        self.dtest = xgb.DMatrix(self.X_test, self.y_test, enable_categorical=True)\n",
    "\n",
    "    def assess_on_test(self):\n",
    "        self.y_preds = self.model.predict(self.X_test)\n",
    "        self.y_proba = self.model.predict_proba(self.X_test)\n",
    "        return sum(self.y_preds == self.y_test) / len(self.y_preds)\n",
    "    \n",
    "    def test_results(self):\n",
    "        self.assess_on_test()\n",
    "        return pd.concat([self.y_preds,self.y_proba,self.y_test])\n",
    "\n",
    "\n",
    "c = Chrystal_Ball(\n",
    "    training_data = t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21804887, 0.7819511 ],\n",
       "       [0.54102314, 0.45897686],\n",
       "       [0.7945338 , 0.2054662 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.70888585, 0.29111415],\n",
       "       [0.68724924, 0.31275076],\n",
       "       [0.78019595, 0.21980403],\n",
       "       [0.7338624 , 0.2661376 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.67617095, 0.32382905],\n",
       "       [0.4699788 , 0.5300212 ],\n",
       "       [0.21207017, 0.78792983],\n",
       "       [0.2157067 , 0.7842933 ],\n",
       "       [0.8093142 , 0.19068582],\n",
       "       [0.51963633, 0.48036367],\n",
       "       [0.24123341, 0.7587666 ],\n",
       "       [0.6150781 , 0.38492188],\n",
       "       [0.52838576, 0.47161424],\n",
       "       [0.18842864, 0.81157136],\n",
       "       [0.63055813, 0.3694419 ],\n",
       "       [0.26824462, 0.7317554 ],\n",
       "       [0.35410088, 0.6458991 ],\n",
       "       [0.21468854, 0.78531146],\n",
       "       [0.772954  , 0.22704603],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.56147563, 0.43852437],\n",
       "       [0.5429758 , 0.45702422],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.6976421 , 0.30235794],\n",
       "       [0.20398957, 0.79601043],\n",
       "       [0.7080114 , 0.29198858],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.33956403, 0.660436  ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.22444642, 0.7755536 ],\n",
       "       [0.80134666, 0.19865333],\n",
       "       [0.78522885, 0.21477117],\n",
       "       [0.35797596, 0.64202404],\n",
       "       [0.727165  , 0.27283505],\n",
       "       [0.18842864, 0.81157136],\n",
       "       [0.21559614, 0.78440386],\n",
       "       [0.6059012 , 0.39409882],\n",
       "       [0.6872469 , 0.3127531 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.43890083, 0.5610992 ],\n",
       "       [0.21425766, 0.78574234],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.5782608 , 0.42173922],\n",
       "       [0.74421346, 0.2557865 ],\n",
       "       [0.19383276, 0.80616724],\n",
       "       [0.18842864, 0.81157136],\n",
       "       [0.75614965, 0.24385032],\n",
       "       [0.78676677, 0.21323323],\n",
       "       [0.5600018 , 0.4399982 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.47188354, 0.52811646],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.23165703, 0.768343  ],\n",
       "       [0.21648997, 0.78351   ],\n",
       "       [0.6292659 , 0.37073407],\n",
       "       [0.5603194 , 0.4396806 ],\n",
       "       [0.3835916 , 0.6164084 ],\n",
       "       [0.37610424, 0.62389576],\n",
       "       [0.3933599 , 0.6066401 ],\n",
       "       [0.67084146, 0.3291585 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.5907643 , 0.40923572],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.27196908, 0.7280309 ],\n",
       "       [0.20233274, 0.79766726],\n",
       "       [0.21052372, 0.7894763 ],\n",
       "       [0.42906475, 0.57093525],\n",
       "       [0.6759789 , 0.32402107],\n",
       "       [0.44016868, 0.5598313 ],\n",
       "       [0.54941624, 0.45058376],\n",
       "       [0.2198059 , 0.7801941 ],\n",
       "       [0.5216825 , 0.4783175 ],\n",
       "       [0.7424141 , 0.25758588],\n",
       "       [0.19628042, 0.8037196 ],\n",
       "       [0.36155826, 0.63844174],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.20261443, 0.7973856 ],\n",
       "       [0.56416947, 0.43583053],\n",
       "       [0.8025128 , 0.19748718],\n",
       "       [0.28634888, 0.7136511 ],\n",
       "       [0.798974  , 0.20102601],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.35646534, 0.64353466],\n",
       "       [0.25727004, 0.74272996],\n",
       "       [0.72576225, 0.27423775],\n",
       "       [0.42286903, 0.577131  ],\n",
       "       [0.47873014, 0.52126986],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.67084146, 0.3291585 ],\n",
       "       [0.5770086 , 0.42299137],\n",
       "       [0.5206271 , 0.47937292],\n",
       "       [0.6138339 , 0.38616607],\n",
       "       [0.18842864, 0.81157136],\n",
       "       [0.65766907, 0.3423309 ],\n",
       "       [0.32455075, 0.67544925],\n",
       "       [0.36397392, 0.6360261 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.541547  , 0.458453  ],\n",
       "       [0.20593911, 0.7940609 ],\n",
       "       [0.7376154 , 0.2623846 ],\n",
       "       [0.22252375, 0.77747625],\n",
       "       [0.3074258 , 0.6925742 ],\n",
       "       [0.25029796, 0.74970204],\n",
       "       [0.7955913 , 0.2044087 ],\n",
       "       [0.32070583, 0.67929417],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.67084146, 0.3291585 ],\n",
       "       [0.69068336, 0.30931664],\n",
       "       [0.69679755, 0.30320245],\n",
       "       [0.21949011, 0.7805099 ],\n",
       "       [0.19329554, 0.80670446],\n",
       "       [0.41359413, 0.5864059 ],\n",
       "       [0.21967494, 0.78032506],\n",
       "       [0.20765853, 0.7923415 ],\n",
       "       [0.7050277 , 0.29497233],\n",
       "       [0.3288465 , 0.6711535 ],\n",
       "       [0.3767419 , 0.6232581 ],\n",
       "       [0.27820134, 0.72179866],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.43091202, 0.569088  ],\n",
       "       [0.7873141 , 0.21268587],\n",
       "       [0.75036854, 0.24963148],\n",
       "       [0.3050751 , 0.6949249 ],\n",
       "       [0.7528792 , 0.24712078],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.51275396, 0.48724604],\n",
       "       [0.3680818 , 0.6319182 ],\n",
       "       [0.40675837, 0.59324163],\n",
       "       [0.260907  , 0.739093  ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.2937467 , 0.7062533 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.2529388 , 0.7470612 ],\n",
       "       [0.32928687, 0.6707131 ],\n",
       "       [0.21800715, 0.78199285],\n",
       "       [0.22699988, 0.7730001 ],\n",
       "       [0.80613095, 0.19386904],\n",
       "       [0.2566858 , 0.7433142 ],\n",
       "       [0.4122427 , 0.5877573 ],\n",
       "       [0.42170632, 0.5782937 ],\n",
       "       [0.5100788 , 0.48992118],\n",
       "       [0.3585623 , 0.6414377 ],\n",
       "       [0.5385473 , 0.4614527 ],\n",
       "       [0.3934114 , 0.6065886 ],\n",
       "       [0.8110622 , 0.18893778],\n",
       "       [0.4296891 , 0.5703109 ],\n",
       "       [0.79195136, 0.20804864],\n",
       "       [0.6276289 , 0.37237105],\n",
       "       [0.77928007, 0.22071996],\n",
       "       [0.27431875, 0.72568125],\n",
       "       [0.7624349 , 0.2375651 ],\n",
       "       [0.39218026, 0.60781974],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.7656955 , 0.23430447],\n",
       "       [0.5390514 , 0.4609486 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.38931406, 0.61068594],\n",
       "       [0.8002608 , 0.1997392 ],\n",
       "       [0.57741547, 0.42258456],\n",
       "       [0.2786482 , 0.7213518 ],\n",
       "       [0.21539962, 0.7846004 ],\n",
       "       [0.6928989 , 0.30710107],\n",
       "       [0.1925615 , 0.8074385 ],\n",
       "       [0.44995648, 0.5500435 ],\n",
       "       [0.31456238, 0.6854376 ],\n",
       "       [0.19246757, 0.8075324 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.6463251 , 0.3536749 ],\n",
       "       [0.23758262, 0.7624174 ],\n",
       "       [0.740142  , 0.25985804],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.64250743, 0.35749257],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.606691  , 0.39330903],\n",
       "       [0.6431818 , 0.35681817],\n",
       "       [0.20335484, 0.79664516],\n",
       "       [0.3096422 , 0.6903578 ],\n",
       "       [0.6467836 , 0.35321638],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.18770862, 0.8122914 ],\n",
       "       [0.774445  , 0.225555  ],\n",
       "       [0.5531353 , 0.44686475],\n",
       "       [0.8125094 , 0.18749061],\n",
       "       [0.36806303, 0.63193697],\n",
       "       [0.2759878 , 0.7240122 ],\n",
       "       [0.78616667, 0.21383333],\n",
       "       [0.20989078, 0.7901092 ],\n",
       "       [0.4996624 , 0.5003376 ],\n",
       "       [0.5995088 , 0.40049118],\n",
       "       [0.24736768, 0.7526323 ],\n",
       "       [0.72453296, 0.27546707]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.y_proba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
